{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lrPVtNMGPhmw"
   },
   "source": [
    "## LAB 2 - COMMON CRAWL DATA COLLECTION\n",
    "Code Reference:- https://www.bellingcat.com/resources/2015/08/13/using-python-to-mine-common-crawl/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SL58vLsiPhmy"
   },
   "source": [
    "#### Submitted by -\n",
    "    Pradeep Kumar Joshi\n",
    "    Abhishek Goswami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrEqAQrBF4-n"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import argparse\n",
    "import time\n",
    "import json\n",
    "from io import BytesIO\n",
    "import gzip\n",
    "import sys\n",
    "import csv\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k5dJnzRHF4-r"
   },
   "outputs": [],
   "source": [
    "## Specifying the Common Crawl Index and Domain to fetch data\n",
    "cc_index = [\"2019-04\",\"2019-09\",\"2019-13\"]\n",
    "cc_domain = \"americanimmigrationcouncil.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sSBkqv3UF4-t"
   },
   "outputs": [],
   "source": [
    "def compute(cc_domain):\n",
    "\n",
    "    data_collect = []\n",
    "    for index in cc_index:\n",
    "        cc_url  = \"http://index.commoncrawl.org/CC-MAIN-\"+index+\"-index?\" \n",
    "        cc_url += \"url=\"+cc_domain+\"&matchType=domain&output=json\" \n",
    "        \n",
    "        ack = requests.get(cc_url)\n",
    "        if ack.status_code == 200:\n",
    "            val_list = ack.content.splitlines()\n",
    "            for val in val_list:\n",
    "                data_collect.append(json.loads(val))\n",
    "    return data_collect        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gHj4hFy4F4-v"
   },
   "outputs": [],
   "source": [
    "def scrappedData(info):\n",
    "\n",
    "    offset, length = int(info['offset']), int(info['length'])\n",
    "    offset_end = offset + length - 1\n",
    "\n",
    "    url_append = 'https://commoncrawl.s3.amazonaws.com/'\n",
    "    acknldge = requests.get(url_append + info['filename'], headers={'Range': 'bytes={}-{}'.format(offset, offset_end)})\n",
    "\n",
    "    info_collect = BytesIO(acknldge.content)\n",
    "    info_unzipped = gzip.GzipFile(fileobj=info_collect)\n",
    "\n",
    "    unzipped_info = info_unzipped.read()\n",
    "    return unzipped_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wDyCq7u9F4-w"
   },
   "outputs": [],
   "source": [
    "def fetchURL(hyper_text,url_fetched):\n",
    "\n",
    "    parser = BeautifulSoup(hyper_text)\n",
    "    loops = parser.find_all(\"a\")\n",
    "    if loops:\n",
    "        for loop in loops:\n",
    "            text_refer = loop.attrs.get(\"href\")\n",
    "            if text_refer is not None:\n",
    "                if cc_domain not in text_refer:\n",
    "                    if text_refer not in url_fetched and text_refer.startswith(\"http\"):\n",
    "                        url_fetched.append(text_refer)\n",
    "    return url_fetched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6dOu-ljLF4-z"
   },
   "outputs": [],
   "source": [
    "### URL COLLECTION\n",
    "def collectarticles_url(data_collect):\n",
    "    url_fetch = []\n",
    "    \n",
    "    for i in data_collect['ack']['docs']:\n",
    "        urls = {}  \n",
    "        urls['url'] = i['web_url']\n",
    "        url_fetched = urls['url']\n",
    "        url_fetch.append(url_fetched)\n",
    "        \n",
    "    return(url_fetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wA55aYt9F4-1",
    "outputId": "1172d8fd-2d4a-4dd3-c533-4dfaf0ee88d0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs fetched for Common Crawl:  1393\n"
     ]
    }
   ],
   "source": [
    "data_collect = compute(cc_domain)\n",
    "url_fetched   = []\n",
    "\n",
    "for doc in data_collect:\n",
    "    hyper_text = scrappedData(doc)\n",
    "    url_fetched = fetchURL(hyper_text,url_fetched)\n",
    "    \n",
    "print(\"URLs fetched for Common Crawl: \", + len(url_fetched)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TsqwSkYiF4-5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## SCRAPING THE DATA FROM URLs\n",
    "cc_finalList = []\n",
    "for i in url_fetched:\n",
    "    try:\n",
    "        req = urllib.request.urlopen(i).read()\n",
    "    except urllib.error.HTTPError as e:\n",
    "        continue\n",
    "        \n",
    "    soup = BeautifulSoup(req)\n",
    "    loop_text = soup.findAll('p')\n",
    "    \n",
    "    data_text = \"\"\n",
    "    \n",
    "    for val in loop_text:\n",
    "        data_text = data_text + val.getText()\n",
    "    cc_finalList.append(data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XJgX4PS3F4_C"
   },
   "outputs": [],
   "source": [
    "## Generating Common Crawl Text File\n",
    "cc_immigDF = pd.DataFrame(cc_finalList)\n",
    "cc_immigDF.to_csv('common_crawl.txt', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sample(for_common_crawl).ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
